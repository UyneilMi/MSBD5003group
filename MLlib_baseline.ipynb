{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "! pip install ucimlrepo"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9OAd3vH-jOK",
    "outputId": "f4618816-6331-4303-a4da-5ad70d67ed22"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.6\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
    "!tar -xzf spark-3.5.1-bin-hadoop3.tgz\n",
    "!ls /content"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCfg1CoQFhJo",
    "outputId": "298b463a-5b5e-41f2-cb92-0d3bfac8dce5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2024-05-05 03:52:43--  https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
      "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 400446614 (382M) [application/x-gzip]\n",
      "Saving to: ‘spark-3.5.1-bin-hadoop3.tgz’\n",
      "\n",
      "spark-3.5.1-bin-had 100%[===================>] 381.90M  44.1MB/s    in 5.4s    \n",
      "\n",
      "2024-05-05 03:53:00 (71.4 MB/s) - ‘spark-3.5.1-bin-hadoop3.tgz’ saved [400446614/400446614]\n",
      "\n",
      "sample_data  spark-3.5.1-bin-hadoop3  spark-3.5.1-bin-hadoop3.tgz\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.join(os.environ[\"SPARK_HOME\"], 'bin')"
   ],
   "metadata": {
    "id": "icrgHXamDxvN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install findspark\n",
    "!pip install -q findspark\n",
    "!pip install py4j\n",
    "!pip install pyspark"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_lrvtR2Fkic",
    "outputId": "bab3f68f-4fcd-4918-a4f8-3bc326f92768"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
      "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import findspark\n",
    "findspark.init()"
   ],
   "metadata": {
    "id": "ZXQ6SONkFmTh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n"
   ],
   "metadata": {
    "id": "AUkm5ZACFpUJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Js2UZnts-idm",
    "outputId": "ebb750de-aae0-4f97-8f09-efe885aa84e3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'uci_id': 602, 'name': 'Dry Bean', 'repository_url': 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/602/data.csv', 'abstract': 'Images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 13611, 'num_features': 16, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2020, 'last_updated': 'Thu Mar 28 2024', 'dataset_doi': '10.24432/C50S4B', 'creators': [], 'intro_paper': {'title': 'Multiclass classification of dry beans using computer vision and machine learning techniques', 'authors': 'M. Koklu, Ilker Ali Özkan', 'published_in': 'Computers and Electronics in Agriculture', 'year': 2020, 'url': 'https://www.semanticscholar.org/paper/e84c31138f2f261d15517d6b6bb8922c3fe597a1', 'doi': '10.1016/j.compag.2020.105507'}, 'additional_info': {'summary': 'Seven different types of dry beans were used in this research, taking into account the features such as form, shape, type, and structure by the market situation. A computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the classification model, images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. Bean images obtained by computer vision system were subjected to segmentation and feature extraction stages, and a total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1.) Area (A): The area of a bean zone and the number of pixels within its boundaries.\\r\\n2.) Perimeter (P): Bean circumference is defined as the length of its border.\\r\\n3.) Major axis length (L): The distance between the ends of the longest line that can be drawn from a bean.\\r\\n4.) Minor axis length (l): The longest line that can be drawn from the bean while standing perpendicular to the main axis.\\r\\n5.) Aspect ratio (K): Defines the relationship between L and l.\\r\\n6.) Eccentricity (Ec): Eccentricity of the ellipse having the same moments as the region.\\r\\n7.) Convex area (C): Number of pixels in the smallest convex polygon that can contain the area of a bean seed.\\r\\n8.) Equivalent diameter (Ed): The diameter of a circle having the same area as a bean seed area.\\r\\n9.) Extent (Ex): The ratio of the pixels in the bounding box to the bean area.\\r\\n10.)Solidity (S): Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.\\r\\n11.)Roundness (R): Calculated with the following formula: (4piA)/(P^2)\\r\\n12.)Compactness (CO): Measures the roundness of an object: Ed/L\\r\\n13.)ShapeFactor1 (SF1)\\r\\n14.)ShapeFactor2 (SF2)\\r\\n15.)ShapeFactor3 (SF3)\\r\\n16.)ShapeFactor4 (SF4)\\r\\n17.)Class (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz and Sira)\\r\\n', 'citation': None}}\n",
      "               name     role         type demographic  \\\n",
      "0              Area  Feature      Integer        None   \n",
      "1         Perimeter  Feature   Continuous        None   \n",
      "2   MajorAxisLength  Feature   Continuous        None   \n",
      "3   MinorAxisLength  Feature   Continuous        None   \n",
      "4       AspectRatio  Feature   Continuous        None   \n",
      "5      Eccentricity  Feature   Continuous        None   \n",
      "6        ConvexArea  Feature      Integer        None   \n",
      "7     EquivDiameter  Feature   Continuous        None   \n",
      "8            Extent  Feature   Continuous        None   \n",
      "9          Solidity  Feature   Continuous        None   \n",
      "10        Roundness  Feature   Continuous        None   \n",
      "11      Compactness  Feature   Continuous        None   \n",
      "12     ShapeFactor1  Feature   Continuous        None   \n",
      "13     ShapeFactor2  Feature   Continuous        None   \n",
      "14     ShapeFactor3  Feature   Continuous        None   \n",
      "15     ShapeFactor4  Feature   Continuous        None   \n",
      "16            Class   Target  Categorical        None   \n",
      "\n",
      "                                          description   units missing_values  \n",
      "0   The area of a bean zone and the number of pixe...  pixels             no  \n",
      "1   Bean circumference is defined as the length of...    None             no  \n",
      "2   The distance between the ends of the longest l...    None             no  \n",
      "3   The longest line that can be drawn from the be...    None             no  \n",
      "4   Defines the relationship between MajorAxisLeng...    None             no  \n",
      "5   Eccentricity of the ellipse having the same mo...    None             no  \n",
      "6   Number of pixels in the smallest convex polygo...    None             no  \n",
      "7   Equivalent diameter: The diameter of a circle ...    None             no  \n",
      "8   The ratio of the pixels in the bounding box to...    None             no  \n",
      "9   Also known as convexity. The ratio of the pixe...    None             no  \n",
      "10  Calculated with the following formula: (4piA)/...    None             no  \n",
      "11                Measures the roundness of an object    Ed/L             no  \n",
      "12                                               None    None             no  \n",
      "13                                               None    None             no  \n",
      "14                                               None    None             no  \n",
      "15                                               None    None             no  \n",
      "16  (Seker, Barbunya, Bombay, Cali, Dermosan, Horo...    None             no  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "dry_bean = fetch_ucirepo(id=602)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = dry_bean.data.features\n",
    "y = dry_bean.data.targets\n",
    "\n",
    "# metadata\n",
    "print(dry_bean.metadata)\n",
    "\n",
    "# variable information\n",
    "print(dry_bean.variables)\n",
    "\n",
    "# from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# # fetch dataset\n",
    "# default_of_credit_card_clients = fetch_ucirepo(id=350)\n",
    "\n",
    "# # data (as pandas dataframes)\n",
    "# X = default_of_credit_card_clients.data.features\n",
    "# y = default_of_credit_card_clients.data.targets\n",
    "\n",
    "# # metadata\n",
    "# print(default_of_credit_card_clients.metadata)\n",
    "\n",
    "# # variable information\n",
    "# print(default_of_credit_card_clients.variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_Zx-2f_Ggdb",
    "outputId": "ae50908a-f63f-4142-d7ff-b934dbd4847a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "os.chdir(\"/content/drive/My Drive/5003\")"
   ],
   "metadata": {
    "id": "Z8w8zG_NHfZb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "csv_file_path = '/content/drive/My Drive/5003/dataset_default.csv'  \n",
    "df.to_csv(csv_file_path, index=False)"
   ],
   "metadata": {
    "id": "bL_scnx9GSEd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "\n",
    "appname = \"RandomForestClassifier\"\n",
    "master = \"local[4]\"\n",
    "conf = SparkConf().setAppName(appname).setMaster(master)\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "data = spark.read.csv(csv_file_path, header=True, inferSchema=True)  "
   ],
   "metadata": {
    "id": "BqhLSQrpI1zW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "dataSet = data.na.fill('0').rdd.map(list)\n",
    "trainData, testData= dataSet.randomSplit([0.7, 0.3], seed=7)\n",
    "trainingSet = trainData.map(lambda x:Row(label=x[-1], features=Vectors.dense(x[:-1]))).toDF()\n",
    "train_num = trainingSet.count()\n",
    "print(\"训练样本数:{}\".format(train_num))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQsUR5COV4WC",
    "outputId": "2fafb2dc-82f1-4b76-8960-495d77159fe2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "训练样本数:9538\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import time"
   ],
   "metadata": {
    "id": "Jkh435Qlksov"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexed\")\n",
    "si_model = stringIndexer.fit(trainingSet)\n",
    "train_tf = si_model.transform(trainingSet)\n",
    "train_tf.show(5)\n",
    "\n",
    "start_time_rf = time.time() \n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    numTrees=100,\n",
    "    maxDepth=10, \n",
    "    maxBins=32, \n",
    "    featureSubsetStrategy=\"auto\", \n",
    "    labelCol=\"indexed\",\n",
    "    seed=7\n",
    ")\n",
    "rfModel = rf.fit(train_tf)\n",
    "\n",
    "\n",
    "end_time_rf = time.time() \n",
    "duration_rf = end_time_rf - start_time_rf  \n"
   ],
   "metadata": {
    "id": "LC5bsDTgJGlD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "72dfbfb4-16ed-4dae-d7b6-640a3ba80eb6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------------------+-------+\n",
      "|label|            features|indexed|\n",
      "+-----+--------------------+-------+\n",
      "|SEKER|[28395.0,610.291,...|    2.0|\n",
      "|SEKER|[28734.0,638.018,...|    2.0|\n",
      "|SEKER|[29380.0,624.11,2...|    2.0|\n",
      "|SEKER|[30008.0,645.884,...|    2.0|\n",
      "|SEKER|[30140.0,620.134,...|    2.0|\n",
      "+-----+--------------------+-------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"模型特征重要性:{}\".format(rfModel.featureImportances))\n",
    "print(\"模型特征数:{}\".format(rfModel.numFeatures))\n"
   ],
   "metadata": {
    "id": "HiinnPVwJGsU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8149cf3f-0c95-4e77-d3c8-6d594679c049"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "模型特征重要性:(16,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],[0.06793265298414411,0.09129955230251494,0.07089378718392163,0.09230719115407454,0.05160536654564456,0.07909676360922413,0.07738561228464973,0.04814301626654028,0.007882199239551153,0.013586361743283499,0.053964295918658305,0.10627326802447228,0.0761770380607167,0.04665455821823015,0.09080602499718646,0.02599231146718751])\n",
      "模型特征数:16\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "testSet = testData.map(lambda x:Row(label=x[-1], features=Vectors.dense(x[:-1]))).toDF()\n",
    "test_num=testSet.count()\n",
    "print(\"测试样本数:{}\".format(test_num))\n",
    "si_model = stringIndexer.fit(testSet)\n",
    "test_tf = si_model.transform(testSet)\n",
    "predictResult = rfModel.transform(test_tf)\n",
    "predictResult.show(5)\n",
    "# spark.stop()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HetDaWjxMacR",
    "outputId": "ff533dd7-2772-492f-cdce-b6ecff17ba72"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "测试样本数:4073\n",
      "+-----+--------------------+-------+--------------------+--------------------+----------+\n",
      "|label|            features|indexed|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+-------+--------------------+--------------------+----------+\n",
      "|SEKER|[30477.0,670.033,...|    2.0|[1.00702201791994...|[0.01007022017919...|       2.0|\n",
      "|SEKER|[31675.0,657.431,...|    2.0|[99.5792117027196...|[0.99579211702719...|       0.0|\n",
      "|SEKER|[31811.0,642.092,...|    2.0|[2.00407280327609...|[0.02004072803276...|       2.0|\n",
      "|SEKER|[31823.0,662.532,...|    2.0|[3.33529990167158...|[0.03335299901671...|       2.0|\n",
      "|SEKER|[31992.0,640.338,...|    2.0|[0.02986068388708...|[2.98606838870856...|       2.0|\n",
      "+-----+--------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "MKWKfMjeGkQZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "columns=predictResult.columns \n",
    "predictResult=predictResult.take(test_num) \n",
    "predictResult=pd.DataFrame(predictResult,columns=columns) \n"
   ],
   "metadata": {
    "id": "9WC5pxoqjIKV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y = list(predictResult['indexed'])\n",
    "y_pred = list(predictResult['prediction'])\n",
    "y_predprob = [x[1] for x in list(predictResult['probability'])]\n",
    "precision_score = metrics.precision_score(y, y_pred, average='weighted')\n",
    "recall_score = metrics.recall_score(y, y_pred, average='weighted')\n",
    "accuracy_score = metrics.accuracy_score(y, y_pred)\n",
    "f1_score = metrics.f1_score(y, y_pred, average='weighted')\n",
    "# auc_score = metrics.roc_auc_score(y, y_predprob)\n",
    "\n"
   ],
   "metadata": {
    "id": "qf_8-2MUOuxS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"标签分布:\", pd.Series(y).value_counts())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RR_M3Nh-ULpW",
    "outputId": "d6b3a0dd-61a6-4fc6-ed9f-cf217f0b22ed"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "标签分布: 0.0    1058\n",
      "1.0     807\n",
      "2.0     595\n",
      "3.0     560\n",
      "4.0     486\n",
      "5.0     388\n",
      "6.0     179\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"随机森林模型性能评估：\")\n",
    "print(\"精确率:\",precision_score )\n",
    "print(\"召回率:\",recall_score )\n",
    "print(\"准确率:\",accuracy_score )\n",
    "print(\"F1分数:\", f1_score)\n",
    "print(f\"随机森林训练时间：{duration_rf:.3f}秒\")\n",
    "#print(\"auc分数:\",auc_score ) "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jax9sMzRULwh",
    "outputId": "7a5d26bf-4e62-4942-a4e2-c3c52ed602cc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "随机森林模型性能评估：\n",
      "精确率: 0.9247320257580561\n",
      "召回率: 0.924380063835011\n",
      "准确率: 0.924380063835011\n",
      "F1分数: 0.9244992615580041\n",
      "随机森林训练时间：25.662秒\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree"
   ],
   "metadata": {
    "id": "O-kSEIWNuNYg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexed\")\n",
    "si_model = stringIndexer.fit(trainingSet)\n",
    "train_tf = si_model.transform(trainingSet)\n",
    "train_tf.show(5)\n",
    "\n",
    "start_time_dt = time.time()  \n",
    "dt = DecisionTreeClassifier(labelCol=\"indexed\", seed=7)\n",
    "dtModel = dt.fit(train_tf)\n",
    "end_time_dt = time.time()\n",
    "duration_dt = end_time_dt - start_time_dt \n",
    "\n",
    "print(\"决策树模型的树深度: {}\".format(dtModel.depth))\n",
    "print(\"决策树模型的节点数: {}\".format(dtModel.numNodes))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1fTIL3suM2v",
    "outputId": "901a9c09-1417-4628-bfc7-af4d786558f4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------------------+-------+\n",
      "|label|            features|indexed|\n",
      "+-----+--------------------+-------+\n",
      "|SEKER|[28395.0,610.291,...|    2.0|\n",
      "|SEKER|[28734.0,638.018,...|    2.0|\n",
      "|SEKER|[29380.0,624.11,2...|    2.0|\n",
      "|SEKER|[30008.0,645.884,...|    2.0|\n",
      "|SEKER|[30140.0,620.134,...|    2.0|\n",
      "+-----+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "决策树模型的树深度: 5\n",
      "决策树模型的节点数: 47\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_tf = si_model.transform(testSet)\n",
    "predictResult_dt = dtModel.transform(test_tf)\n",
    "predictResult_dt.show(5)\n",
    "\n",
    "predictResult_list_dt = predictResult_dt.select(\"indexed\", \"prediction\").collect()\n",
    "y_true = [row['indexed'] for row in predictResult_list_dt]\n",
    "y_pred = [row['prediction'] for row in predictResult_list_dt]\n",
    "\n",
    "precision_score_dt = metrics.precision_score(y_true, y_pred, average='weighted')\n",
    "recall_score_dt = metrics.recall_score(y_true, y_pred, average='weighted')\n",
    "accuracy_score_dt = metrics.accuracy_score(y_true, y_pred)\n",
    "f1_score_dt = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"决策树模型性能评估：\")\n",
    "print(\"精确率:\", precision_score_dt)\n",
    "print(\"召回率:\", recall_score_dt)\n",
    "print(\"准确率:\", accuracy_score_dt)\n",
    "print(\"F1分数:\", f1_score_dt)\n",
    "print(f\"决策树训练时间：{duration_dt:.3f}秒\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPhX3_Xdu4ZX",
    "outputId": "05b2f059-3644-4a5c-96ed-282662845ec4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------------------+-------+--------------------+--------------------+----------+\n",
      "|label|            features|indexed|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+-------+--------------------+--------------------+----------+\n",
      "|SEKER|[30477.0,670.033,...|    2.0|[0.0,0.0,37.0,0.0...|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "|SEKER|[31675.0,657.431,...|    2.0|[1846.0,22.0,16.0...|[0.97827239003709...|       0.0|\n",
      "|SEKER|[31811.0,642.092,...|    2.0|[1846.0,22.0,16.0...|[0.97827239003709...|       0.0|\n",
      "|SEKER|[31823.0,662.532,...|    2.0|[1846.0,22.0,16.0...|[0.97827239003709...|       0.0|\n",
      "|SEKER|[31992.0,640.338,...|    2.0|[16.0,8.0,1190.0,...|[0.01313628899835...|       2.0|\n",
      "+-----+--------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "决策树模型性能评估：\n",
      "精确率: 0.8991869757222919\n",
      "召回率: 0.8966363859562976\n",
      "准确率: 0.8966363859562976\n",
      "F1分数: 0.8970322088635054\n",
      "决策树训练时间：6.474秒\n"
     ]
    }
   ]
  }
 ]
}
